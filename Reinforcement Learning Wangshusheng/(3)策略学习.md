# 策略学习

![image-20230109184516966](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230109184516966.png)

![image-20230109190150388](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230109190150388.png)

其中theta为神经网络的参数

## 策略梯度

![image-20230109201214438](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230109201214438.png)

## 策略梯度的两种等价形式

![image-20230109201322481](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230109201322481.png)

## 策略学习的步骤：

![image-20230110161451636](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230110161451636.png)

## 计算qt的两种算法

### 1、Reinforce算法



![image-20230110161925853](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230110161925853.png)

## 2、actor-critic方法

组成：

![image-20230110164306471](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230110164306471.png)

### 更新网络参数的步骤

![image-20230110165425342](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230110165425342.png)

## 更新Actor

![image-20230111183101997](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230111183101997.png)

## 更新Critic

![image-20230111183111400](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230111183111400.png)

## 算法步骤

![image-20230111190417560](https://img-1301878935.cos.ap-nanjing.myqcloud.com//typora/image-20230111190417560.png)

第九步论文中常用delta t代替qt

